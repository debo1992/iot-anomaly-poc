# IoT Smart Home â€” Anomaly Detection Proof-of-Concept

ğŸ“Œ Overview

This repository contains a full anomaly detection pipeline for smart homes. It simulates realistic multi-sensor data, injects anomalies, trains multiple deep learning architectures, and prepares them for deployment on edge devices.

The goal: move beyond brittle threshold rules and deliver adaptive, learning-based monitoring for safety, efficiency, and security.


```text
iot-anomaly-poc/
â”œâ”€â”€ main.py                 # Training pipeline (multi-model)
â”œâ”€â”€ build_multiuser_datasets.py  # Generate multi-user datasets
â”œâ”€â”€ datasets/               # Synthetic IoT datasets + generator
â”‚   â”œâ”€â”€ anomaly_dataset.py  # Custom PyTorch dataset + sampler
â”‚   â”œâ”€â”€ generate_data.py    # Sensor simulation + anomaly injection
â”‚   â”œâ”€â”€ data/               # Train/val CSVs
â”‚   â””â”€â”€ README_datasets.md
â”œâ”€â”€ models/                 # Baseline deep learning models
â”‚   â”œâ”€â”€ lstm_basic.py
â”‚   â”œâ”€â”€ cnn_basic.py
â”‚   â”œâ”€â”€ tcn_basic.py
â”‚   â”œâ”€â”€ transformer_basic.py
â”‚   â””â”€â”€ initialize_model.py
â”œâ”€â”€ utils/                  # Training utilities
â”‚   â”œâ”€â”€ evaluation_metrics.py  # Confusion matrix, PR curves, F1
â”‚   â”œâ”€â”€ logging.py             # MLflow + W&B logging
â”‚   â”œâ”€â”€ class_weight.py        # Handle class imbalance
â”‚   â””â”€â”€ losses.py              # Focal loss, weighted CE
â”œâ”€â”€ tests/                 # Post-training tools
â”‚   â”œâ”€â”€ load_eval_model.py     # Baseline model evaluation
â”‚   â”œâ”€â”€ quantize_model.py      # Dynamic & static quantization 
â”‚   â”œâ”€â”€ drift_monitor.py       # Data drift detection
â”‚   â””â”€â”€ benchmark_compare.py   # Compare model sizes + ONNX
â”œâ”€â”€ outputs/               # Saved models
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## Overview
This repository contains a complete proof-of-concept for anomaly detection on multi-sensor smart-home time-series data. It simulates sensors, injects anomalies, and runs a lightweight detection pipeline that uses both interpretable rules and an unsupervised multivariate model.

# IoT Anomaly Detection POC

## Iter 1 - Sensors: Baic dataset with anomalies but no drift simulation

## Iter 2 - Sensors
- **Temperature (Â°C, Living Room)**  
  - Baseline 21 Â°C Â± daily cycle, with slow drift (+0.05 Â°C/week).  
  - Anomalies: sensor failure (constant/frozen values).  

- **Humidity (%RH, Bathroom)**  
  - Baseline 45 %RH, spikes to 70â€“90 % during showers.  
  - Drift: +0.1 %RH/week.  
  - Anomalies: spikes outside shower schedule.  

- **Fridge Power (W)**  
  - Baseline ~150 W, with compressor cycling Â±10 W.  
  - Anomalies: power failure (drop to 0 W).  

- **Front Door (binary)**  
  - 0 = closed, 1 = open.  
  - Anomalies: opening during 00:00â€“05:00 (nighttime).  

- **Fire Alarm (binary)**  
  - 0 = off, 1 = alarm triggered.  
  - Overrides all anomalies.  

## Labels
Each timestamp has a label:  
- 0 â†’ Normal  
- 1 â†’ Temperature anomaly  
- 2 â†’ Humidity anomaly  
- 3 â†’ Fridge anomaly  
- 4 â†’ Door anomaly  
- 5 â†’ Fire alarm (highest priority)  

## Dataset Organization
- `train_users/` â†’ 80 users, hourly data over 6 months.  
- `val_users/` â†’ 20 users.  
- `train_all.csv`, `val_all.csv` â†’ concatenated datasets.  

## Limitations
- Synthetic dataset: not based on real hardware logs.  
- Drift patterns are modeled linearly, while real drift can be nonlinear or environment-dependent.  
- Event frequencies are approximated; actual user behavior varies.  
- Rare anomalies (like fire alarms) are injected more frequently than real-world rates for training utility.  

## ğŸ“Š Dataset Organization
- **`train_users/`** â†’ 80 simulated households (6 months)  
- **`val_users/`** â†’ 20 households  
- **`train_all.csv`, `val_all.csv`** â†’ aggregated datasets  

Includes **seasonality** (winter/summer drift) and **random anomaly durations** (2 hours â€“ 1 week) for realism.  

---

## ğŸ¤– Models
Implemented baselines:
- ğŸ§  **LSTM** â€” sequential modeling, baseline  
- âš¡ **CNN** â€” 1D convolution with dilations for long context  
- â±ï¸ **TCN** â€” temporal convolutional network with residuals  
- ğŸ¯ **Transformer** â€” attention-based sequence encoder  

---

## ğŸ§ª Training Pipeline
- ğŸ² **Weighted sampling** for class imbalance  
- ğŸ“‰ **Custom losses**: CrossEntropy, Focal Loss  
- â³ **Early stopping** + best model checkpointing  
- ğŸ“Š **Experiment tracking** via MLflow (confusion matrices & PR curves)  
- ğŸŸ£ **W&B optional logging**  

---

## ğŸ“¦ Deployment Prep
- ğŸ“ **Quantization** (PyTorch dynamic/static: CNN, TCN, LSTM)  
- ğŸ”„ **ONNX export** for cross-platform inference  
- âš–ï¸ **Model size benchmarking** (original vs quantized vs ONNX)  
- ğŸ“¡ **Drift monitoring** for household behavior changes  
- ğŸ³ **Docker-ready packaging**  

---

## ğŸš€ Roadmap
- âœ… **Synthetic dataset generation** + anomaly injection  
- âœ… **Multi-model training & benchmarking**  
- âœ… **Quantization & ONNX conversion**  
- âœ… **Drift monitoring**  
- ğŸ”œ **Deploy REST API** for smart home integration  
- ğŸ”œ **Pilot with real IoT data**  


