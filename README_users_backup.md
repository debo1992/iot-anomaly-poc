# IoT Smart Home â€” Anomaly Detection Proof-of-Concept

ğŸ“Œ Overview

This repository contains a full anomaly detection pipeline for smart homes. It simulates realistic multi-sensor data, injects anomalies, trains multiple deep learning architectures, and prepares them for deployment on edge devices.

The goal: move beyond brittle threshold rules and deliver adaptive, learning-based monitoring for safety, efficiency, and security.


```text
iot-anomaly-poc/
â”œâ”€â”€ main.py                 # Training pipeline (multi-model)
â”œâ”€â”€ build_multiuser_datasets.py  # Generate multi-user datasets
â”œâ”€â”€ datasets/               # Synthetic IoT datasets + generator
â”‚   â”œâ”€â”€ anomaly_dataset.py  # Custom PyTorch dataset + sampler
â”‚   â”œâ”€â”€ generate_data.py    # Sensor simulation + anomaly injection
â”‚   â”œâ”€â”€ data/               # Train/val CSVs
â”‚   â””â”€â”€ README_datasets.md
â”œâ”€â”€ models/                 # Baseline deep learning models
â”‚   â”œâ”€â”€ lstm_basic.py
â”‚   â”œâ”€â”€ cnn_basic.py
â”‚   â”œâ”€â”€ tcn_basic.py
â”‚   â”œâ”€â”€ transformer_basic.py
â”‚   â””â”€â”€ initialize_model.py
â”œâ”€â”€ utils/                  # Training utilities
â”‚   â”œâ”€â”€ evaluation_metrics.py  # Confusion matrix, PR curves, F1
â”‚   â”œâ”€â”€ logging.py             # MLflow + W&B logging
â”‚   â”œâ”€â”€ class_weight.py        # Handle class imbalance
â”‚   â””â”€â”€ losses.py              # Focal loss, weighted CE
â”œâ”€â”€ tests/                 # Post-training tools
â”‚   â”œâ”€â”€ load_eval_model.py     # Baseline model evaluation
â”‚   â”œâ”€â”€ quantize_model.py      # Dynamic & static quantization 
â”‚   â”œâ”€â”€ drift_monitor.py       # Data drift detection
â”‚   â””â”€â”€ benchmark_compare.py   # Compare model sizes + ONNX
â”œâ”€â”€ outputs/               # Saved models
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Overview
This repository contains a complete proof-of-concept for anomaly detection on multi-sensor smart-home time-series data. It simulates sensors, injects anomalies, and runs a lightweight detection pipeline that uses both interpretable rules and an unsupervised multivariate model.

# IoT Anomaly Detection POC

## Iter 1 - Sensors: Baic dataset with anomalies but no drift simulation

## Iter 2 - Sensors
- **Temperature (Â°C, Living Room)**  
  - Baseline 21 Â°C Â± daily cycle, with slow drift (+0.05 Â°C/week).  
  - Anomalies: sensor failure (constant/frozen values).  

- **Humidity (%RH, Bathroom)**  
  - Baseline 45 %RH, spikes to 70â€“90 % during showers.  
  - Drift: +0.1 %RH/week.  
  - Anomalies: spikes outside shower schedule.  

- **Fridge Power (W)**  
  - Baseline ~150 W, with compressor cycling Â±10 W.  
  - Anomalies: power failure (drop to 0 W).  

- **Front Door (binary)**  
  - 0 = closed, 1 = open.  
  - Anomalies: opening during 00:00â€“05:00 (nighttime).  

- **Fire Alarm (binary)**  
  - 0 = off, 1 = alarm triggered.  
  - Overrides all anomalies.  

## Labels
Each timestamp has a label:  
- 0 â†’ Normal  
- 1 â†’ Temperature anomaly  
- 2 â†’ Humidity anomaly  
- 3 â†’ Fridge anomaly  
- 4 â†’ Door anomaly  
- 5 â†’ Fire alarm (highest priority)  

## Dataset Organization
- `train_users/` â†’ 80 users, hourly data over 6 months.  
- `val_users/` â†’ 20 users.  
- `train_all.csv`, `val_all.csv` â†’ concatenated datasets.  

## Limitations
- Synthetic dataset: not based on real hardware logs.  
- Drift patterns are modeled linearly, while real drift can be nonlinear or environment-dependent.  
- Event frequencies are approximated; actual user behavior varies.  
- Rare anomalies (like fire alarms) are injected more frequently than real-world rates for training utility.  

## ğŸ“Š Dataset Organization
- **`train_users/`** â†’ 80 simulated households (6 months)  
- **`val_users/`** â†’ 20 households  
- **`train_all.csv`, `val_all.csv`** â†’ aggregated datasets  

Includes **seasonality** (winter/summer drift) and **random anomaly durations** (2 hours â€“ 1 week) for realism.  

---

## ğŸ¤– Models
Implemented baselines:
- ğŸ§  **LSTM** â€” sequential modeling, baseline  
- âš¡ **CNN** â€” 1D convolution with dilations for long context  
- â±ï¸ **TCN** â€” temporal convolutional network with residuals  
- ğŸ¯ **Transformer** â€” attention-based sequence encoder  

---

## ğŸ§ª Training Pipeline
- ğŸ² **Weighted sampling** for class imbalance  
- ğŸ“‰ **Custom losses**: CrossEntropy, Focal Loss  
- â³ **Early stopping** + best model checkpointing  
- ğŸ“Š **Experiment tracking** via MLflow (confusion matrices & PR curves)  
- ğŸŸ£ **W&B optional logging**  

---

## ğŸ“¦ Deployment Prep
- ğŸ“ **Quantization** (PyTorch dynamic/static: CNN, TCN, LSTM)  
- ğŸ”„ **ONNX export** for cross-platform inference  
- âš–ï¸ **Model size benchmarking** (original vs quantized vs ONNX)  
- ğŸ“¡ **Drift monitoring** for household behavior changes  
- ğŸ³ **Docker-ready packaging**  

---

## ğŸš€ Roadmap
- âœ… **Synthetic dataset generation** + anomaly injection  
- âœ… **Multi-model training & benchmarking**  
- âœ… **Quantization & ONNX conversion**  
- âœ… **Drift monitoring**  
- ğŸ”œ **Deploy REST API** for smart home integration  
- ğŸ”œ **Pilot with real IoT data**

## ğŸš€ Usage

### ğŸ§± Setup

```bash
# (1) Create and activate a virtual environment (optional)
python3 -m venv venv_name
source venv_name/bin/activate  

# (2) Install required packages
pip install -r requirements.txt
```

### ğŸ“¦ Build Dataset

Before training, build the dataset:

```text
python3 main.py --build-data
```

### Training Default config:
```
python3 main.py
```

This will train all supported models using built-in default parameters. The options for available models are:

- DilatedCNN

- CNN_DILATION

- LSTM

- CNN

- TRANSFORMER

- TCN


To run the model with the stored config
```
python3 main.py --config configs/main_train_config.json
```
If you want to override some configs, modify the example below:
```
python3 main.py --config configs/train_config.json --epochs 5 --model_type LSTM
```

```
| Argument            | Type  | Default     | Description                                 |
| ------------------- | ----- | ----------- | ------------------------------------------- |
| `--build-data`      | flag  | off         | Build the dataset from scratch              |
| `--config`          | str   | None        | Path to a JSON config file                  |
| `--model_type`      | str   | LSTM        | Model to train (`LSTM`, `CNN`, `TCN`, etc.) |
| `--epochs`          | int   | 10          | Number of training epochs                   |
| `--batch_size`      | int   | 64          | Batch size                                  |
| `--lr`              | float | 0.001       | Learning rate                               |
| `--patience`        | int   | 5           | Early stopping patience                     |
| `--window_size`     | int   | 32          | Time-series window size                     |
| `--loss_type`       | str   | weighted_ce | Type of loss function (`weighted_ce`, etc.) |
| `--balanced_loader` | bool  | False       | Use class-balanced data loading             |
| `--no-log`          | flag  | off         | Disable MLflow logging (dont use right now) |
```

### Quantize Model
Create the quantized model with PQT based on model type. Eport the model to onnx and save models.
```bash
python3 quantize_model.py
```

### Benchmark tests
```
python3 benchmark_compare.py
```



